<h2> MLOps Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(1).pdf" style="text-decoration:none;">Attend and Attack: Attention Guided Adversarial Attacks on Visual Question Answering Models</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(2).pdf" style="text-decoration:none;">Multimodal Medical Image Retrieval based on Latent Topic Modeling</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(3).pdf" style="text-decoration:none;">Unifying and Merging Well-trained Deep Neural Networks for Inference Stage</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(4).pdf" style="text-decoration:none;">Semi-Supervised Multimodal Deep Learning for RGB-D Object Recognition</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(5).pdf" style="text-decoration:none;">Microsoft COCO: Common Objects in Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(6).pdf" style="text-decoration:none;">Deep Fragment Embeddings for Bidirectional Image Sentence Mapping</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(7).pdf" style="text-decoration:none;">Show and Tell: A Neural Image Caption Generator</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(8).pdf" style="text-decoration:none;"> Deep Visual-Semantic Alignments for Generating Image Descriptions </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(9).pdf" style="text-decoration:none;">A Dataset for Movie Description</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(10).pdf" style="text-decoration:none;">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(11).pdf" style="text-decoration:none;">What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(12).pdf" style="text-decoration:none;">VQA: Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(13).pdf" style="text-decoration:none;">Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(14).pdf" style="text-decoration:none;">Multimodal Deep Learning for Robust RGB-D Object Recognition</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(15).pdf" style="text-decoration:none;">Order-Embeddings of Images and Language</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(16).pdf" style="text-decoration:none;">VisualWord2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(17).pdf" style="text-decoration:none;">MovieQA: Understanding Stories in Movies through Question-Answering</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(18).pdf" style="text-decoration:none;">Hollywood in Homes: Crowdsourcing Data
Collection for Activity Understanding</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(19).pdf" style="text-decoration:none;">Generative Adversarial Text to Image Synthesis</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(20).pdf" style="text-decoration:none;">Learning to Communicate with
Deep Multi-Agent Reinforcement Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(21).pdf" style="text-decoration:none;">Review Networks for Caption Generation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(22).pdf" style="text-decoration:none;">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(23).pdf" style="text-decoration:none;">Towards Transparent AI Systems:
Interpreting Visual Question Answering Models</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(24).pdf" style="text-decoration:none;">Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(25).pdf" style="text-decoration:none;">SoundNet: Learning Sound
Representations from Unlabeled Video</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(26).pdf" style="text-decoration:none;">Visual Dialog</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(27).pdf" style="text-decoration:none;">Multi-Agent Cooperation and the Emergence of (Natural) Language</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(28).pdf" style="text-decoration:none;">Deep Voice: Real-time Neural Text-to-Speech</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(29).pdf" style="text-decoration:none;">Zero-Shot Learning - The Good, the Bad and the Ugly </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(30).pdf" style="text-decoration:none;">Emergence of Grounded Compositional Language in Multi-Agent Populations</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(31).pdf" style="text-decoration:none;">Learning Robust Visual-Semantic Embeddings</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(32).pdf" style="text-decoration:none;">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(33).pdf" style="text-decoration:none;">Towards Building Large Scale Multimodal Domain-Aware Conversation Systems</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(34).pdf" style="text-decoration:none;">Generating Descriptions with Grounded and Co-Referenced People</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(35).pdf" style="text-decoration:none;">Deep Multimodal Representation Learning from Temporal Data</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(36).pdf" style="text-decoration:none;">Learning to Reason: End-to-End Module Networks for Visual Question Answering</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(37).pdf" style="text-decoration:none;">End-to-End Multimodal Emotion Recognition using Deep Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(38).pdf" style="text-decoration:none;">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(39).pdf" style="text-decoration:none;">Gated-Attention Architectures for Task-Oriented Language Grounding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(40).pdf" style="text-decoration:none;">Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(41).pdf" style="text-decoration:none;">SCAN: Learning Hierarchical Compositional Visual Concepts</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(42).pdf" style="text-decoration:none;">Tensor Fusion Network for Multimodal Sentiment Analysis</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(43).pdf" style="text-decoration:none;">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(44).pdf" style="text-decoration:none;">Localizing Moments in Video with Natural Language</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(45).pdf" style="text-decoration:none;">Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(46).pdf" style="text-decoration:none;">Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(47).pdf" style="text-decoration:none;">Fooling Vision and Language Models
Despite Localization and Attention Mechanism</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(48).pdf" style="text-decoration:none;">Emergent Translation in Multi-Agent Communication</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(49).pdf" style="text-decoration:none;">Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(50).pdf" style="text-decoration:none;">Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(51).pdf" style="text-decoration:none;">Learning Multi-ModalWord Representation Grounded in Visual Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(52).pdf" style="text-decoration:none;">Look, Imagine and Match:
Improving Textual-Visual Cross-Modal Retrieval with Generative Models</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(53).pdf" style="text-decoration:none;">Neural Motifs: Scene Graph Parsing with Global Context</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(54).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(55).pdf" style="text-decoration:none;">Video Captioning via Hierarchical Reinforcement Learning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(56).pdf" style="text-decoration:none;">Embodied Question Answering </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(57).pdf" style="text-decoration:none;">Don't Just Assume; Look and Answer:
Overcoming Priors for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(58).pdf" style="text-decoration:none;">Grounding Referring Expressions in Images by Variational Context</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(59).pdf" style="text-decoration:none;">Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(60).pdf" style="text-decoration:none;">Semi-supervised Multimodal Hashing </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(61).pdf" style="text-decoration:none;"> Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(62).pdf" style="text-decoration:none;">Zero-Resource Neural Machine Translation with Multi-Agent Communication Game</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(63).pdf" style="text-decoration:none;">A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(64).pdf" style="text-decoration:none;">Multimodal Generative Models for Scalable Weakly-Supervised Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/MLOps-Papers/blob/master/ml(65).pdf" style="text-decoration:none;">Learning to Count Objects in Natural Images for Visual Question Answering </a></li> 

   </ul>
